{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b228080",
   "metadata": {},
   "source": [
    "# Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "from gp_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9561683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPC:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a Gaussian Process Classifier (GPC) object.\n",
    "        The GPC is not fitted upon initialization.\n",
    "        \"\"\"\n",
    "        self.theta = None\n",
    "    \n",
    "    def exp_kernel(self, X1, X2, theta):\n",
    "        \"\"\"\n",
    "        Isotropic squared exponential kernel function.\n",
    "\n",
    "        Args:\n",
    "            X1: Array of m points (m x d).\n",
    "            X2: Array of n points (n x d).\n",
    "            theta: Kernel parameters (array-like).\n",
    "\n",
    "        Returns:\n",
    "            K: Gram matrix (m x n) computed using the squared exponential kernel.\n",
    "        \"\"\"\n",
    "\n",
    "        sqdist = (\n",
    "            np.sum(X1 ** 2, 1).reshape(-1, 1)\n",
    "            + np.sum(X2 ** 2, 1)\n",
    "            - 2 * np.dot(X1, X2.T)\n",
    "        )\n",
    "        return theta[1] ** 2 * np.exp(-0.5 / theta[0] ** 2 * sqdist)\n",
    "\n",
    "    def K_(self, X, theta, diag_only=False, nu=1e-5):\n",
    "        \"\"\"\n",
    "        Helper function to compute the covariance matrix K.\n",
    "\n",
    "        Args:\n",
    "            X: Data points (n x d).\n",
    "            theta: Kernel parameters (array-like).\n",
    "            diag_only: If True, compute only the diagonal elements of K.\n",
    "            nu: Small constant to add to the diagonal of K for numerical stability.\n",
    "\n",
    "        Returns:\n",
    "            K: Covariance matrix (n x n) or its diagonal elements.\n",
    "        \"\"\"\n",
    "        if diag_only:\n",
    "            # Specific solution for isotropic\n",
    "            # squared exponential kernel.\n",
    "            return theta[1] ** 2 + nu\n",
    "        else:\n",
    "            return self.exp_kernel(X, X, theta) + nu * np.eye(X.shape[0])\n",
    "\n",
    "    def W_(self, a):\n",
    "        \"\"\"\n",
    "        Helper function to compute matrix W.\n",
    "\n",
    "        Args:\n",
    "            a: Logit values (n x 1).\n",
    "\n",
    "        Returns:\n",
    "            W: Diagonal matrix of weights (n x n).\n",
    "        \"\"\"\n",
    "        r = sigmoid(a) * (1 - sigmoid(a))\n",
    "        return np.diag(r.ravel())\n",
    "\n",
    "    def posterior_mode(self, X, y, K_a, max_iter=10, tol=1e-9):\n",
    "        \"\"\"\n",
    "        Computes the mode of posterior p(a|y).\n",
    "\n",
    "        Args:\n",
    "            X: Data points (n x d).\n",
    "            y: Target values (n x 1).\n",
    "            K_a: Covariance matrix K_a (n x n).\n",
    "            max_iter: Maximum number of iterations for optimization.\n",
    "            tol: Tolerance for convergence.\n",
    "\n",
    "        Returns:\n",
    "            a_h: Mode of the posterior p(a|y) (n x 1).\n",
    "        \"\"\"\n",
    "        a_h = np.zeros_like(y)\n",
    "        I = np.eye(X.shape[0])\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            W = self.W_(a_h)\n",
    "            Q_inv = np.linalg.pinv(I + W @ K_a)\n",
    "            a_h_new = (K_a @ Q_inv).dot(y - sigmoid(a_h) + W.dot(a_h))\n",
    "            a_h_diff = np.abs(a_h_new - a_h)\n",
    "            a_h = a_h_new\n",
    "\n",
    "            if not np.any(a_h_diff > tol):\n",
    "                break\n",
    "\n",
    "        return a_h\n",
    "\n",
    "    def nll_fn(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Data points (n x d).\n",
    "            y: Target values (n x 1).\n",
    "\n",
    "        Returns:\n",
    "            nll: Negative log-likelihood function.\n",
    "        \"\"\"\n",
    "\n",
    "        y = y.ravel()\n",
    "\n",
    "        def nll(theta):\n",
    "            K_a = self.K_(X, theta)\n",
    "            K_a_inv = np.linalg.inv(K_a)\n",
    "\n",
    "            # posterior mode depends on theta (via K)\n",
    "            a_h = self.posterior_mode(X, y, K_a).ravel()\n",
    "            W = self.W_(a_h)\n",
    "\n",
    "            ll = (\n",
    "                -0.5 * a_h.T.dot(K_a_inv).dot(a_h)\n",
    "                - 0.5 * np.linalg.slogdet(K_a)[1]\n",
    "                - 0.5 * np.linalg.slogdet(W + K_a_inv)[1]\n",
    "                + y.dot(a_h)\n",
    "                - np.sum(np.log(1.0 + np.exp(a_h)))\n",
    "            )\n",
    "\n",
    "            return -ll\n",
    "\n",
    "        return nll\n",
    "    \n",
    "    def mean_var(self, X_test):\n",
    "        \"\"\"\n",
    "        Computes the mean and variance of logits at points X_test\n",
    "        given training data X, y, and kernel parameters theta.\n",
    "\n",
    "        Args:\n",
    "            X_test: Test data points (n_test x d).\n",
    "\n",
    "        Returns:\n",
    "            a_test_mu: Mean of logits (n_test x 1).\n",
    "            a_test_var: Variance of logits (n_test x 1).\n",
    "        \"\"\"\n",
    "        K_a = self.K_(self.X, self.theta)\n",
    "        K_s = self.exp_kernel(self.X, X_test, self.theta)\n",
    "        a_h = self.posterior_mode(self.X, self.y, K_a)\n",
    "\n",
    "        W_inv = np.linalg.pinv(self.W_(a_h))\n",
    "        R_inv = np.linalg.pinv(W_inv + K_a)\n",
    "\n",
    "        a_test_mu = K_s.T.dot(self.y - sigmoid(a_h))\n",
    "        # Compute variances only (= diagonal) instead of full covariance matrix\n",
    "        a_test_var = self.K_(X_test, self.theta, diag_only=True) - np.sum((R_inv @ K_s) * K_s, axis=0).reshape(-1, 1)\n",
    "\n",
    "        return a_test_mu, a_test_var\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes the probability of points X being in class 1.\n",
    "        GPC must be fitted before calling `predict`.\n",
    "        \"\"\"\n",
    "        a_mu, a_var = self.mean_var(X)\n",
    "        kappa = 1.0 / np.sqrt(1.0 + np.pi * a_var / 8)\n",
    "        return sigmoid(kappa * a_mu)\n",
    "    \n",
    "    def predict_params(self, X_test):\n",
    "        \"\"\"\n",
    "        Computes the mean and variance of logits at points X_test\n",
    "        given training data X, y and kernel parameters theta.\n",
    "        GPC must be fitted before calling `predict_params`.\n",
    "        \"\"\"\n",
    "        \n",
    "        K_a = self.K_(self.X, self.theta)\n",
    "        K_s = self.exp_kernel(self.X, X_test, self.theta)\n",
    "        a_h = self.posterior_mode(self.X, y, K_a)\n",
    "\n",
    "        W_inv = np.linalg.inv(self.W_(a_h))\n",
    "        R_inv = np.linalg.inv(W_inv + K_a)\n",
    "\n",
    "        a_test_mu = K_s.T.dot(y - sigmoid(a_h))\n",
    "        # Compute variances only (= diagonal) instead of full covariance matrix\n",
    "        a_test_var = self.K_(X_test, self.theta, diag_only=True) - np.sum((R_inv @ K_s) * K_s, axis=0).reshape(-1, 1)\n",
    "\n",
    "        return a_test_mu, a_test_var\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        res = minimize(\n",
    "            self.nll_fn(X, y),\n",
    "            [1, 1],\n",
    "            bounds=((1e-3, None), (1e-3, None)),\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "        self.theta = res.x\n",
    "        \n",
    "        print(f\"Kernel parameters: {self.theta}, NLL = {res.fun:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a7680",
   "metadata": {},
   "source": [
    "## Example A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(200, noise=0.4, random_state=42)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "plot_data_2D(X, y)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GPC()\n",
    "gp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x, grid_y = np.mgrid[-4:4:200j, -4:4:200j]\n",
    "grid = np.stack([grid_x, grid_y], axis=-1)\n",
    "\n",
    "y_pred = gp.predict(grid.reshape(-1, 2)).reshape(*grid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 7))\n",
    "plot_pt_2D(grid_x, grid_y, y_pred)\n",
    "plot_db_2D(grid_x, grid_y, y_pred, decision_boundary=0.5)\n",
    "plot_data_2D(X, y)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test_var = gp.predict_params(grid.reshape(-1, 2))[1].reshape(*grid_x.shape)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.contourf(grid_x, grid_y, a_test_var, alpha=0.3, cmap='viridis_r', levels=np.linspace(0, 15, 11))\n",
    "plt.colorbar(label=\"Uncertainty\")\n",
    "plot_db_2D(grid_x, grid_y, y_pred, decision_boundary=0.5)\n",
    "plot_data_2D(X, y)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e367e6",
   "metadata": {},
   "source": [
    "## Example B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c063828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(n_samples=400, noise=0.25, random_state=42, factor=0.25)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_2D(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GPC()\n",
    "gp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb132c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x, grid_y = np.mgrid[-1.5:2:200j, -1.5:2:200j]\n",
    "grid = np.stack([grid_x, grid_y], axis=-1)\n",
    "\n",
    "\n",
    "y_pred = gp.predict(grid.reshape(-1, 2)).reshape(*grid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 7))\n",
    "plot_pt_2D(grid_x, grid_y, y_pred)\n",
    "plot_db_2D(grid_x, grid_y, y_pred, decision_boundary=0.5)\n",
    "plot_data_2D(X, y)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7476d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "g = ax.plot_surface(grid_x, grid_y, y_pred, cmap=\"viridis\")\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$z$')\n",
    "fig.colorbar(g, label=\"$p(y=1|x_1,x_2)$\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca6d4f",
   "metadata": {},
   "source": [
    "## Example C: Banknote authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"banknotes.csv\", header=None)\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "X = df[[0, 3]].to_numpy()\n",
    "y = df[4].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_2D(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x, grid_y = np.mgrid[-1.5:2:200j, -1.5:2:200j]\n",
    "grid = np.stack([grid_x, grid_y], axis=-1)\n",
    "\n",
    "\n",
    "y_pred = gp.predict(grid.reshape(-1, 2)).reshape(*grid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49118921",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GPC()\n",
    "gp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x, grid_y = np.mgrid[-1.5:2:200j, -1.5:2:200j]\n",
    "grid = np.stack([grid_x, grid_y], axis=-1)\n",
    "\n",
    "\n",
    "y_pred = gp.predict(grid.reshape(-1, 2)).reshape(*grid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 7))\n",
    "plot_pt_2D(grid_x, grid_y, y_pred)\n",
    "plot_db_2D(grid_x, grid_y, y_pred, decision_boundary=0.5)\n",
    "plot_data_2D(X, y)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test_var = gp.predict_params(grid.reshape(-1, 2))[1].reshape(*grid_x.shape)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.contourf(grid_x, grid_y, a_test_var, alpha=0.3, cmap='viridis_r', levels=np.linspace(0, 15, 11))\n",
    "plt.colorbar(label=\"Uncertainty\")\n",
    "plot_db_2D(grid_x, grid_y, y_pred, decision_boundary=0.5)\n",
    "plot_data_2D(X, y)\n",
    "plt.legend();\n",
    "plt.savefig(\"bn_unc.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
